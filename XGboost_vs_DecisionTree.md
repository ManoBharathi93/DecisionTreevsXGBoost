# Decision tree classifier

A decision tree classifier is a simple and interpretable model that builds a tree-like structure to classify data. 
It works by partitioning the feature space into smaller subspaces based on the feature values and making decisions based on the resulting partitions. 
Decision trees are prone to overfitting and can be sensitive to changes in the data, resulting in poor generalization performance.

# XGBoost (eXtreme Gradient Boosting) classifier
XGBoost (eXtreme Gradient Boosting) classifier is a more advanced and sophisticated model that uses an ensemble of decision trees to achieve higher accuracy. 
It works by building decision trees in a sequential manner, where each subsequent tree is trained to correct the errors of the previous tree. 
XGBoost uses a technique called gradient boosting, which optimizes the loss function to minimize the difference between predicted and actual values.

# Inference
XGBoost tends to outperform decision tree classifiers in terms of accuracy and robustness to changes in the data. 
However, XGBoost requires more computation resources and is more complex to tune compared to decision tree classifiers. 
